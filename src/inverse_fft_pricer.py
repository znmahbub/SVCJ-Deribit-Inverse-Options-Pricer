"""
Pricing European inverse call and put options via the Carr–Madan FFT
===================================================================

This module implements a fast Fourier transform (FFT) based pricer for
European options on a futures contract under several models: Black,
Heston and the stochastic volatility with correlated jumps (SVCJ) model.
It follows the Carr–Madan (1999) algorithm as described in the user's
thesis and detailed in Appendix A of the supplied PDF.

The core idea is to compute a grid of regular (USD-denominated) call
prices across strikes via the FFT, then convert to inverse (coin)
denominated prices using a simple division by the current futures price
and put–call parity. A single FFT yields
prices for an entire grid of strikes, which makes the procedure very
efficient when calibrating a model to cross‑sectional option data.

The module exposes the following high-level function:

``price_inverse_option(model, K, T, F0, params, option_type="call", fft_params=None, return_grid=False)``

Given a chosen model ("black", "heston" or "svcj"), a strike or array of
strikes ``K`` (in USD), time to maturity ``T`` (in years), the current
futures price ``F0`` and the model parameters, this function returns
the price of a European inverse call or put option in coin units.  If
``return_grid`` is ``True`` it also returns the entire strike grid and
call price grid generated by the FFT.

Internally, the module uses three layers:
  - **Characteristic functions** for each model, returning the moment
    generating function of ``X_T = log F_T`` under the futures measure
    evaluated at complex arguments.  These functions are vectorised
    and accept complex numpy arrays.
  - **Carr–Madan FFT engine** that discretises the integral
    representation of the damped call price, applies quadrature weights
    (trapezoidal or Simpson), and uses an FFT to recover prices across a
    log‑strike grid.
  - **Wrapper** converting the resulting USD call prices to inverse
    option prices and performing interpolation for arbitrary strikes.

To improve calibration performance the FFT results are cached: when
repeatedly pricing the same maturity and parameter set the precomputed
strike and call grids are reused.

The module requires only NumPy and does not rely on external
libraries such as SciPy.  The numerical integration in the SVCJ
characteristic function is performed using Gauss–Legendre quadrature.
"""

from __future__ import annotations

from dataclasses import dataclass
from functools import lru_cache
import numpy as np
from numpy.fft import fft  # Use numpy's FFT for speed

###############################################################################
# Dataclass for FFT configuration
###############################################################################

@dataclass(frozen=True)
class FFTParams:
    """Configuration parameters for the Carr–Madan FFT.

    Attributes
    ----------
    N : int
        Number of grid points in the frequency/log‑strike domain.  Must be a
        power of two for FFT efficiency.
    alpha : float
        Exponential damping factor.  Must be chosen so that the characteristic
        function exists for ``u - i(alpha+1)``.  Typical values are 1.0–2.0 for
        call options.
    eta : float
        Spacing of the frequency grid.  The maximum frequency is
        ``v_max = (N - 1) * eta``.  Together with ``N`` it determines the
        spacing of the log‑strike grid via ``lambda_ = 2*pi/(N*eta)``.
    b : float
        Minimum log‑strike on the output grid.  The output strikes are
        ``exp(b + u*lambda_)`` for ``u = 0, …, N-1``.  Choose ``b`` so
        that the grid covers the strikes of interest.
    use_simpson : bool
        If ``True``, use Simpson’s rule for quadrature weights; otherwise use
        the trapezoidal rule.  Simpson’s rule offers higher accuracy for
        smooth integrands but requires ``N`` to be even.
    """
    N: int = 2 ** 12
    alpha: float = 1.5
    eta: float = 0.1
    b: float = -5.0
    use_simpson: bool = True

    def __post_init__(self) -> None:
        # Validate grid size for Simpson's rule
        if self.use_simpson and self.N % 2 != 0:
            raise ValueError("N must be even when using Simpson's rule")

###############################################################################
# Characteristic functions for the models
###############################################################################

def cf_black(u: np.ndarray, T: float, F0: float, sigma: float) -> np.ndarray:
    """Characteristic function of log-futures under the Black model.

    Parameters
    ----------
    u : np.ndarray
        Complex arguments where the characteristic function is evaluated.  Can
        be a scalar or a vector.
    T : float
        Time to maturity in years.
    F0 : float
        Current futures price.  Appears as ``exp(i*u*log(F0))`` in the CF.
    sigma : float
        Volatility parameter of the Black model (constant).

    Returns
    -------
    np.ndarray
        The characteristic function evaluated at ``u``.
    """
    # For the Black model under the futures measure, log‑futures follow
    # dX_t = -0.5*sigma^2 dt + sigma dW_t.  The solution is
    # X_T = X_0 - 0.5*sigma^2 T + sigma (W_T - W_0).
    # Thus φ(u) = exp(i*u*(log(F0) - 0.5*sigma^2*T) - 0.5*sigma^2*u^2*T).
    iu = 1j * u
    drift = -0.5 * sigma * sigma * T
    return np.exp(iu * (np.log(F0) + drift) - 0.5 * sigma * sigma * u * u * T)


def cf_heston(
    u: np.ndarray,
    T: float,
    F0: float,
    kappa: float,
    theta: float,
    sigma_v: float,
    rho: float,
    v0: float,
) -> np.ndarray:
    """Characteristic function of log‑futures under the Heston model.

    Parameters
    ----------
    u : np.ndarray
        Complex arguments.
    T : float
        Time to maturity.
    F0 : float
        Current futures price.
    kappa, theta, sigma_v, rho, v0 : float
        Heston parameters: mean reversion speed, long‑run variance, vol of vol,
        correlation, and initial variance.

    Returns
    -------
    np.ndarray
        Characteristic function values at ``u``.
    """
    tau = T
    # Ensure array for vectorised operations
    u = np.asarray(u, dtype=np.complex128)
    iu = 1j * u
    # Discriminant d(u)
    d = np.sqrt((kappa - rho * sigma_v * iu) ** 2 + sigma_v * sigma_v * (u ** 2 + iu))
    # Enforce positive real part to avoid branch cut discontinuities
    # If real part is negative, flip the sign
    d = np.where(np.real(d) < 0, -d, d)
    # g(u)
    g = (kappa - rho * sigma_v * iu - d) / (kappa - rho * sigma_v * iu + d)
    # B(τ; u)
    exp_dt = np.exp(-d * tau)
    B = (kappa - rho * sigma_v * iu - d) / (sigma_v * sigma_v) * (1 - exp_dt) / (1 - g * exp_dt)
    # A(τ; u)
    log_term = np.log((1 - g * exp_dt) / (1 - g))
    A = (
        kappa
        * theta
        / (sigma_v * sigma_v)
        * ((kappa - rho * sigma_v * iu - d) * tau - 2 * log_term)
    )
    # Characteristic function
    return np.exp(A + B * v0 + iu * np.log(F0))


def cf_svcj(
    u: np.ndarray,
    T: float,
    F0: float,
    kappa: float,
    theta: float,
    sigma_v: float,
    rho: float,
    v0: float,
    lam: float,
    ell_y: float,
    sigma_y: float,
    ell_v: float,
    rho_j: float,
    quad_nodes: int = 32,
) -> np.ndarray:
    """Characteristic function of log‑futures under the SVCJ model.

    Parameters
    ----------
    u : np.ndarray
        Complex arguments.
    T : float
        Time to maturity.
    F0 : float
        Current futures price.
    kappa, theta, sigma_v, rho, v0 : float
        Stochastic volatility parameters as in Heston.
    lam : float
        Jump intensity.
    ell_y, sigma_y : float
        Mean and standard deviation of the log‑return jump conditional on the
        variance jump.
    ell_v : float
        Mean of the variance jump (exponential distribution).
    rho_j : float
        Dependence parameter between return and variance jump sizes.
    quad_nodes : int, optional
        Number of Gauss–Legendre nodes for the time integral in the jump
        component.  A larger value yields higher accuracy but increases
        computation time.  Defaults to 32.

    Returns
    -------
    np.ndarray
        Characteristic function evaluated at ``u``.
    """
    tau = T
    u_arr = np.asarray(u, dtype=np.complex128)
    scalar_input = (u_arr.ndim == 0)
    u = np.atleast_1d(u_arr)

    # Basic parameter domain checks (avoid singularities in jump MGF)
    if ell_v <= 0:
        raise ValueError("SVCJ requires ell_v > 0 (mean of variance jump size exponential distribution).")
    if 1.0 - ell_v * rho_j <= 0:
        raise ValueError(
            "SVCJ requires 1 - ell_v * rho_j > 0 so that E[e^{rho_j Z}] is finite (martingale drift adjustment)."
        )
    iu = 1j * u
    # Heston-like discriminant d(u) and g(u)
    d = np.sqrt((kappa - rho * sigma_v * iu) ** 2 + sigma_v * sigma_v * (u ** 2 + iu))
    d = np.where(np.real(d) < 0, -d, d)
    g = (kappa - rho * sigma_v * iu - d) / (kappa - rho * sigma_v * iu + d)
    # B(τ; u)
    exp_dt = np.exp(-d * tau)
    B_tau = (kappa - rho * sigma_v * iu - d) / (sigma_v * sigma_v) * (1 - exp_dt) / (1 - g * exp_dt)
    # Diffusion component A_diff(τ; u)
    log_term = np.log((1 - g * exp_dt) / (1 - g))
    A_diff = (
        kappa
        * theta
        / (sigma_v * sigma_v)
        * ((kappa - rho * sigma_v * iu - d) * tau - 2 * log_term)
    )
    # Jump contribution A_jump(τ; u)
    # Precompute κF
    kappa_F = np.exp(ell_y + 0.5 * sigma_y * sigma_y) / (1.0 - ell_v * rho_j) - 1.0
    # Gauss–Legendre quadrature on [0, τ]
    # Nodes x in [-1,1], weights w.  Map to s in [0, τ] via s = 0.5*τ*(x+1).
    nodes, weights = np.polynomial.legendre.leggauss(quad_nodes)
    s = 0.5 * tau * (nodes + 1.0)
    ds = 0.5 * tau * weights  # weight factor includes Jacobian
    # Compute B(s; u) for all s.  Shape of result (len(s), len(u)) using broadcasting.
    # We use explicit broadcasting: d has shape (len(u),), s has shape (len(s),),
    # and the result B_s has shape (len(s), len(u)).
    d_mat = d[np.newaxis, :]
    g_mat = g[np.newaxis, :]
    exp_dsmat = np.exp(-d_mat * s[:, np.newaxis])
    B_s = (
        (kappa - rho * sigma_v * iu)[np.newaxis, :]
        - d_mat
    ) / (sigma_v * sigma_v) * (1 - exp_dsmat) / (1 - g_mat * exp_dsmat)
    # Function M(u, B): mgf of the joint jump distribution
    # M(u,B) = exp(iu*ell_y - 0.5*u^2*sigma_y^2) / (1 - ell_v * (B + i*u*rho_j))
    # We broadcast u and B accordingly.  u has shape (len(u),,), B_s has shape (len(s), len(u)).
    # Denominator for each s,u
    # NOTE: the return jump mean depends linearly on the variance jump size.
    # With Z ~ Exp(mean=ell_v) and Y|Z ~ N(ell_y + rho_j*Z, sigma_y^2), we have
    # E[exp(iu Y + B Z)] = exp(iu*ell_y - 0.5*sigma_y^2*u^2) / (1 - ell_v*(B + iu*rho_j)).
    denom = 1.0 - ell_v * (B_s + iu[np.newaxis, :] * rho_j)
    M = np.exp(iu[np.newaxis, :] * ell_y - 0.5 * (sigma_y * sigma_y) * (u ** 2)[np.newaxis, :]) / denom
    # Integrand: M(u,B(s)) - 1 - i*u*κF
    integrand = M - 1.0 - (iu[np.newaxis, :] * kappa_F)
    # Integrate over s: sum over axis 0
    A_jump = lam * np.sum(ds[:, np.newaxis] * integrand, axis=0)
    # Combine A and B to get φ
    A = A_diff + A_jump
    phi = np.exp(A + B_tau * v0 + iu * np.log(F0))
    return phi[0] if scalar_input else phi

###############################################################################
# FFT pricing engine
###############################################################################

def _quadrature_weights(N: int, use_simpson: bool) -> np.ndarray:
    """Return quadrature weights for the discretised integral.

    For the trapezoidal rule the weights are 0.5 at the endpoints and 1 in
    between.  For Simpson’s rule they are (1/3, 4/3, 2/3, …, 4/3, 1/3).  The
    factor 1/3 is applied here so that multiplying by ``eta`` gives the
    appropriate integral weight.
    """
    if use_simpson:
        # Simpson's rule requires N even and yields weights scaled by 1/3
        w = np.empty(N, dtype=float)
        w[0] = 1.0 / 3.0
        w[-1] = 1.0 / 3.0
        # For indices 1..N-2
        for j in range(1, N - 1):
            if j % 2 == 1:
                w[j] = 4.0 / 3.0
            else:
                w[j] = 2.0 / 3.0
        return w
    else:
        # Trapezoidal rule
        w = np.ones(N, dtype=float)
        w[0] = 0.5
        w[-1] = 0.5
        return w


def carr_madan_call_fft(
    cf: callable,
    T: float,
    F0: float,
    params: tuple,
    fft_params: FFTParams,
) -> tuple[np.ndarray, np.ndarray]:
    """Compute a grid of regular call prices via the Carr–Madan FFT.

    Parameters
    ----------
    cf : callable
        Characteristic function ``cf(u, T, F0, *params)`` returning φ(u) for the
        specified model.  Must accept vectorised complex ``u``.
    T : float
        Time to maturity.
    F0 : float
        Current futures price.
    params : tuple
        Model parameters to pass into ``cf`` after ``u``, ``T`` and ``F0``.
    fft_params : FFTParams
        Configuration for the FFT grid.

    Returns
    -------
    (K_grid, C_grid) : tuple of np.ndarray
        ``K_grid`` contains the strikes (ascending) and ``C_grid`` contains the
        corresponding regular call prices in USD.
    """
    N = fft_params.N
    alpha = fft_params.alpha
    eta = fft_params.eta
    b = fft_params.b
    # Frequency grid v_j = j*eta
    j = np.arange(N)
    v = j * eta
    # Compute Ψ(v) = φ(v - i*(α+1)) / (α^2 + α - v^2 + i(2α+1)v)
    u_shift = v - 1j * (alpha + 1.0)
    phi_vals = cf(u_shift, T, F0, *params)
    denom = (alpha * alpha + alpha - v * v) + 1j * (2.0 * alpha + 1.0) * v
    psi = phi_vals / denom
    # Quadrature weights and scaling by η
    w = _quadrature_weights(N, fft_params.use_simpson)
    # Sequence x_j = e^{-i v_j b} ψ(v_j) w_j η
    x = np.exp(-1j * v * b) * psi * w * eta
    # FFT to compute damped call values on log‑strike grid
    y = fft(x)
    # Log‑strike grid k_u = b + u*λ, λη = 2π/N
    lambda_ = 2.0 * np.pi / (N * eta)
    k = b + j * lambda_
    # Damped call prices c(k_u) = (1/π) Re(y_u)
    c = np.real(y) / np.pi
    # Regular call prices C(K) = e^{-α k} c(k)
    C = np.exp(-alpha * k) * c
    # Convert log‑strike to strike K
    K_grid = np.exp(k)
    return K_grid, C

###############################################################################
# Caching decorator for FFT results
###############################################################################

def _cache_key(model_name: str, T: float, F0: float, params: tuple, fft_params: FFTParams) -> tuple:
    """Construct a hashable cache key for a pricing grid."""
    return (
        model_name,
        T,
        F0,
        tuple(params),
        fft_params.N,
        fft_params.alpha,
        fft_params.eta,
        fft_params.b,
        fft_params.use_simpson,
    )


def _get_pricing_grid(
    model_name: str,
    cf: callable,
    T: float,
    F0: float,
    params: tuple,
    fft_params: FFTParams,
) -> tuple[np.ndarray, np.ndarray]:
    """Retrieve or compute the pricing grid for a given maturity and parameter set.

    Uses a least‑recently‑used cache to avoid redundant FFT evaluations.
    """
    key = _cache_key(model_name, T, F0, params, fft_params)
    # Use functools.lru_cache by wrapping around this helper
    return _cached_pricing_grid(key, cf, T, F0, params, fft_params)


@lru_cache(maxsize=None)
def _cached_pricing_grid(
    key: tuple,
    cf: callable,
    T: float,
    F0: float,
    params: tuple,
    fft_params: FFTParams,
) -> tuple[np.ndarray, np.ndarray]:
    """Cache wrapper for computing pricing grids.  The key is ignored except to
    make lru_cache depend on the inputs implicitly."""
    return carr_madan_call_fft(cf, T, F0, params, fft_params)

###############################################################################
# Public pricing function
###############################################################################

def price_inverse_option(
    model: str,
    K: float | np.ndarray,
    T: float,
    F0: float,
    params: dict,
    *,
    option_type: str = "call",
    fft_params: FFTParams | None = None,
    return_grid: bool = False,
) -> tuple[np.ndarray, np.ndarray] | np.ndarray:
    """Price European inverse call or put options under the specified model.

    Parameters
    ----------
    model : {'black', 'heston', 'svcj'}
        Which model to use.  Case insensitive.
    K : float or array_like
        Strike(s) in USD per coin.  Can be a scalar or a 1‑D array.
    T : float
        Time to maturity in years.
    F0 : float
        Current futures price (USD per coin).
    params : dict
        Dictionary of model parameters.  For the Black model, pass
        ``{'sigma': value}``.  For Heston, pass
        ``{'kappa': ..., 'theta': ..., 'sigma_v': ..., 'rho': ..., 'v0': ...}``.
        For SVCJ, in addition to the Heston parameters include
        ``{'lam': ..., 'ell_y': ..., 'sigma_y': ..., 'ell_v': ..., 'rho_j': ...}``.
    option_type : {'call', 'put'}, optional
        Which type of inverse option to price.  Defaults to 'call'.
    fft_params : FFTParams, optional
        Configuration for the FFT.  If not provided, a sensible default is
        created.  Adjust ``b`` to ensure the grid covers the strikes of
        interest.
    return_grid : bool, optional
        If ``True``, return the entire strike grid and USD call price grid
        alongside the requested inverse option price(s).

    Returns
    -------
    price_coin : float or np.ndarray
        Price(s) of the inverse option(s) in coin units.  If ``return_grid`` is
        ``True`` the return value is a tuple ``(price_coin, K_grid, C_grid)``.
    """
    model_lower = model.lower()
    if fft_params is None:
        fft_params = FFTParams()
    # Extract model parameters and select characteristic function
    if model_lower == "black":
        cf_func = cf_black
        # Parameters order: sigma
        sigma = params.get("sigma")
        if sigma is None:
            raise ValueError("Black model requires parameter 'sigma'")
        param_tuple = (sigma,)
    elif model_lower == "heston":
        cf_func = cf_heston
        try:
            param_tuple = (
                params["kappa"],
                params["theta"],
                params["sigma_v"],
                params["rho"],
                params["v0"],
            )
        except KeyError as e:
            raise ValueError(f"Missing Heston parameter: {e}")
    elif model_lower == "svcj":
        cf_func = cf_svcj
        try:
            param_tuple = (
                params["kappa"],
                params["theta"],
                params["sigma_v"],
                params["rho"],
                params["v0"],
                params["lam"],
                params["ell_y"],
                params["sigma_y"],
                params["ell_v"],
                params["rho_j"],
            )
        except KeyError as e:
            raise ValueError(f"Missing SVCJ parameter: {e}")
    else:
        raise ValueError(f"Unsupported model '{model}'. Choose from 'black', 'heston', 'svcj'.")
    # Compute or fetch pricing grid
    K_grid, C_grid = _get_pricing_grid(model_lower, cf_func, T, F0, param_tuple, fft_params)
    # Interpolate USD call prices to requested strikes
    K = np.asarray(K, dtype=float)
    # Ensure monotonic ascending grid for interpolation; the FFT grid is ascending by construction
    call_prices_usd = np.interp(K, K_grid, C_grid)
    # Convert to coin units: call_coin = call_usd / F0
    call_coin = call_prices_usd / F0
    call_coin = np.clip(call_coin, 0.0, 1.0)
    if option_type.lower() == "call":
        price_coin = call_coin
    elif option_type.lower() == "put":
        # Put–call parity for inverse options: C_coin - P_coin = 1 - K/F0
        price_coin = call_coin - (1.0 - K / F0)
        price_coin = np.maximum(price_coin, 0.0)
    else:
        raise ValueError("option_type must be 'call' or 'put'")
    if return_grid:
        return price_coin, K_grid, C_grid
    return price_coin

###############################################################################
# Analytic / semi-analytic reference prices (for testing)
###############################################################################

def _norm_cdf(x: np.ndarray | float) -> np.ndarray | float:
    """Standard normal CDF using a fast rational approximation.

    This avoids a SciPy dependency while staying accurate enough for pricing
    checks (absolute error typically < 1e-7).
    """
    x_arr = np.asarray(x, dtype=float)
    # Abramowitz & Stegun 7.1.26 approximation
    a1, a2, a3, a4, a5 = 0.319381530, -0.356563782, 1.781477937, -1.821255978, 1.330274429
    p = 0.2316419
    abs_x = np.abs(x_arr)
    t = 1.0 / (1.0 + p * abs_x)
    poly = (((((a5 * t + a4) * t + a3) * t + a2) * t + a1) * t)
    pdf = np.exp(-0.5 * abs_x * abs_x) / np.sqrt(2.0 * np.pi)
    cdf_pos = 1.0 - pdf * poly
    cdf = np.where(x_arr >= 0.0, cdf_pos, 1.0 - cdf_pos)
    if np.isscalar(x):
        return float(cdf)
    return cdf


def black76_call_price(F0: float, K: float | np.ndarray, T: float, sigma: float) -> float | np.ndarray:
    """Analytic Black–76 call price (undiscounted; r=0)."""
    K_arr = np.asarray(K, dtype=float)
    scalar = K_arr.ndim == 0
    K = K_arr
    vol = sigma * np.sqrt(T)
    # Handle T=0 / vol=0 gracefully
    if np.isclose(vol, 0.0):
        out = np.maximum(F0 - K, 0.0)
        return float(out) if scalar else out
    d1 = (np.log(F0 / K) + 0.5 * vol * vol) / vol
    d2 = d1 - vol
    out = F0 * _norm_cdf(d1) - K * _norm_cdf(d2)
    return float(out) if scalar else out


def black76_put_price(F0: float, K: float | np.ndarray, T: float, sigma: float) -> float | np.ndarray:
    """Analytic Black–76 put price (undiscounted; r=0)."""
    K_arr = np.asarray(K, dtype=float)
    scalar = K_arr.ndim == 0
    K = K_arr
    vol = sigma * np.sqrt(T)
    if np.isclose(vol, 0.0):
        out = np.maximum(K - F0, 0.0)
        return float(out) if scalar else out
    d1 = (np.log(F0 / K) + 0.5 * vol * vol) / vol
    d2 = d1 - vol
    out = K * _norm_cdf(-d2) - F0 * _norm_cdf(-d1)
    return float(out) if scalar else out


def _heston_p1p2(
    F0: float,
    K: float | np.ndarray,
    T: float,
    kappa: float,
    theta: float,
    sigma_v: float,
    rho: float,
    v0: float,
    *,
    u_max: float = 200.0,
    n: int = 256,
    kind: str = "call",
) -> tuple[np.ndarray, np.ndarray, np.ndarray]:
    """Compute (K, P1, P2) for Heston via Gil–Pelaez inversion.

    Parameters
    ----------
    kind : {"call","put"}
        For "call", P1 and P2 correspond to probabilities for the event F_T > K.
        For "put", they correspond to probabilities for the event F_T < K, computed
        directly by flipping the sign in the inversion (rather than using complements).

    Notes
    -----
    Uses the characteristic function of X_T = log(F_T). Assumes r = 0 for pricing on
    futures/forwards (as in Black-76 / Deribit conventions).
    """
    if kind not in {"call", "put"}:
        raise ValueError("kind must be 'call' or 'put'")

    K_arr = np.atleast_1d(np.asarray(K, dtype=float))
    if np.any(K_arr <= 0):
        raise ValueError("All strikes K must be strictly positive.")
    lnK = np.log(K_arr)

    # Gauss–Legendre nodes on [0, u_max]
    nodes, weights = np.polynomial.legendre.leggauss(int(n))
    u = 0.5 * u_max * (nodes + 1.0)
    w = 0.5 * u_max * weights

    # Characteristic function values
    phi_u = cf_heston(u, T, F0, kappa, theta, sigma_v, rho, v0)
    phi_u_minus_i = cf_heston(u - 1j, T, F0, kappa, theta, sigma_v, rho, v0)
    phi_minus_i = cf_heston(np.array([-1j]), T, F0, kappa, theta, sigma_v, rho, v0)[0]

    # exp(-i u lnK) with broadcasting (n, m)
    exp_term = np.exp(-1j * u[:, np.newaxis] * lnK[np.newaxis, :])
    denom = (1j * u)[:, np.newaxis]

    integrand2 = exp_term * (phi_u[:, np.newaxis] / denom)
    integrand1 = exp_term * (phi_u_minus_i[:, np.newaxis] / (denom * phi_minus_i))

    sgn = 1.0 if kind == "call" else -1.0
    P2 = 0.5 + sgn * (1.0 / np.pi) * np.sum(w[:, np.newaxis] * np.real(integrand2), axis=0)
    P1 = 0.5 + sgn * (1.0 / np.pi) * np.sum(w[:, np.newaxis] * np.real(integrand1), axis=0)

    # Numerically, tiny overshoots can occur
    P1 = np.clip(P1, 0.0, 1.0)
    P2 = np.clip(P2, 0.0, 1.0)
    return K_arr, P1, P2


def heston_call_price(
    F0: float,
    K: float | np.ndarray,
    T: float,
    kappa: float,
    theta: float,
    sigma_v: float,
    rho: float,
    v0: float,
    *,
    u_max: float = 200.0,
    n: int = 256,
) -> float | np.ndarray:
    """Semi-analytical Heston call price on a futures/forward (USD), with r = 0.

    C = F0 * P1 - K * P2, where P1 and P2 are obtained by Gil–Pelaez inversion.

    This is mainly intended as a consistency check of the Heston characteristic
    function against the Carr–Madan FFT engine.
    """
    K_arr, P1, P2 = _heston_p1p2(
        F0,
        K,
        T,
        kappa,
        theta,
        sigma_v,
        rho,
        v0,
        u_max=u_max,
        n=n,
        kind="call",
    )
    C = F0 * P1 - K_arr * P2
    C = np.maximum(C, 0.0)
    if np.isscalar(K):
        return float(C[0])
    return C


def heston_put_price(
    F0: float,
    K: float | np.ndarray,
    T: float,
    kappa: float,
    theta: float,
    sigma_v: float,
    rho: float,
    v0: float,
    *,
    u_max: float = 200.0,
    n: int = 256,
) -> float | np.ndarray:
    """Semi-analytical Heston put price on a futures/forward (USD), with r = 0.

    P = K * P2_put - F0 * P1_put, where probabilities are computed for the event
    F_T < K via Gil–Pelaez inversion (no put-call parity shortcut).
    """
    K_arr, P1, P2 = _heston_p1p2(
        F0,
        K,
        T,
        kappa,
        theta,
        sigma_v,
        rho,
        v0,
        u_max=u_max,
        n=n,
        kind="put",
    )
    P = K_arr * P2 - F0 * P1
    P = np.maximum(P, 0.0)
    if np.isscalar(K):
        return float(P[0])
    return P
